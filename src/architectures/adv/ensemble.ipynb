{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author: Johanna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this notebook to do a basic ensemble on different architectures. This is a simple average ensemble like introduced in <br/>\n",
    "https://arxiv.org/abs/1911.06475 <br/>\n",
    "and does not use any meta learner to combine predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we do the usual setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "basepath = Path(os.getcwd())\n",
    "# make sure your working directory is the repository root.\n",
    "if basepath.name != \"idp-radio-1\":\n",
    "    os.chdir(basepath.parent.parent.parent)\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "os.getcwd()\n",
    "\n",
    "import os \n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "# Run this before loading other dependencies, otherwise they might occupy memory on gpu 0 by default and it will stay that way\n",
    "\n",
    "# Specify which GPU(s) to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Or 2, 3, etc. other than 0\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(device_count={'GPU': 1}, allow_soft_placement=True, log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1.0\n",
    "tf.compat.v1.Session(config=config)\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.densenet import DenseNet121, DenseNet169\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet101V2\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from src.architectures.simple.simple_base import SimpleBaseArchitecture\n",
    "from src.architectures.adv.guendel19 import densenet\n",
    "import numpy as np\n",
    "\n",
    "from src.architectures.benchmarks.benchmark import Benchmark, Experiment\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from src.architectures.benchmarks.benchmark_definitions import Chexpert_Benchmark, Chestxray14_Benchmark, simple_architecture_experiment, generate_benchmarks, METRICS, SINGLE_CLASS_METRICS, CHEXPERT_COLUMNS, CHESTXRAY14_COLUMNS\n",
    "from src.metrics.metrics import F2Score\n",
    "from src.metrics.losses import WeightedBinaryCrossentropy, BinaryCrossentropy, compute_class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!remote_access/get_tunnels.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify our benchmark for the ensemble. All training for the single ensemble models is done here to ensure that the dataset split as well as all preprocessing and hyperparameters are the same for all ensemble members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_12 = ['Enlarged Cardiomediastinum',\n",
    "                    'Cardiomegaly',\n",
    "                    'Lung Opacity',\n",
    "                    'Lung Lesion',\n",
    "                    'Edema',\n",
    "                    'Consolidation',\n",
    "                    'Pneumonia',\n",
    "                    'Atelectasis',\n",
    "                    'Pneumothorax',\n",
    "                    'Pleural Effusion',\n",
    "                    'Pleural Other',\n",
    "                    'Fracture']\n",
    "columns_5 =  ['Cardiomegaly',\n",
    "                'Edema',\n",
    "                'Consolidation',\n",
    "                'Atelectasis',\n",
    "                'Pleural Effusion']\n",
    "\n",
    "uzeros = ['Cardiomegaly',\n",
    "        'Enlarged Cardiomediastinum',\n",
    "        'Lung Opacity',\n",
    "        'Lung Lesion',\n",
    "        'Consolidation',\n",
    "        'Pneumothorax',\n",
    "        'Pleural Effusion']\n",
    "\n",
    "uones = ['Edema',\n",
    "        'Atelectasis',\n",
    "        'Fracture',\n",
    "        'Pleural Other',\n",
    "        'Pneumonia',]\n",
    "\n",
    "upsample_factors = {\n",
    "    \"Enlarged Cardiomediastinum\": 1,\n",
    "    \"Lung Lesion\":1,\n",
    "    #\"Pneumothorax\":1,\n",
    "    #\"Pneumonia\":1,\n",
    "    \"Pleural Other\":2,\n",
    "    \"Fracture\":2,\n",
    "}\n",
    "transformations_0 = {\"hist_equalization\":{}}\n",
    "transformations_1 = { \"gaussian_blur\":{\"kernal_size\":3}, \"hist_equalization\":{}}\n",
    "transformations_2 = {\"unsharp_mask\":{\"radius\":2, \"amount\":1}}\n",
    "transformations_3 = {\"windowing\"}\n",
    "transformations_4 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "bce_benchmark = Chexpert_Benchmark (path = Path(os.environ.get(\"CHEXPERT_DATASET_DIRECTORY\")),\n",
    "                                     name=\"Chexpert_Masked_CWBCE_L1Normed_E5_B32_C0_N12_AugAffine_sharp21_U75_D256_DS9505_1LR4_LF1_Adam_Upsampled\",\n",
    "                                     classes=columns_12,\n",
    "                                     #train_labels = \"train.csv\",\n",
    "                                     train_labels = \"nofinding_train.csv\",\n",
    "                                     test_labels = \"test.csv\",\n",
    "                                     nan_replacement = -1, #float(\"NaN\"),\n",
    "                                     u_enc = [uzeros, uones],\n",
    "                                     epochs=3,\n",
    "                                     batch_size=32,\n",
    "                                     crop = False,\n",
    "                                     dim=(256, 256),\n",
    "                                     loss = BinaryCrossentropy(),\n",
    "                                     use_class_weights = False,\n",
    "                                     upsample_factors = upsample_factors,\n",
    "                                     metrics=METRICS,\n",
    "                                     single_class_metrics=SINGLE_CLASS_METRICS,\n",
    "                                     optimizer = Adam(learning_rate=1e-4, clipnorm=1),\n",
    "                                     lr_factor = 0.1,\n",
    "                                     augmentation = \"affine\",\n",
    "                                     transformations = transformations_2,\n",
    "                                     split_seed = 6122156,\n",
    "                                     split_valid_size = 0.05, \n",
    "                                     preprocess_input_fn = tf.keras.applications.inception_resnet_v2.preprocess_input)\n",
    "\n",
    "\n",
    "bce_benchmark.loss = WeightedBinaryCrossentropy(bce_benchmark.positive_weights,\n",
    "                                                bce_benchmark.negative_weights)\n",
    "\n",
    "bce_chexpert_exp = simple_architecture_experiment(bce_benchmark, InceptionResNetV2, bce_benchmark.label_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_chexpert_exp.benchmark.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_chexpert_exp.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_chexpert_exp.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_chexpert_exp.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the individual members of the ensemble and do predictions on the test data generator. Those predictions are then averaged and evaluated with the sklearn classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = \"models/InceptionResNetV2_Chexpert_BCE_NoNorm_E5_B32_C0_N12_AugAffine_sharp21_U75_D256_DS9505_1LR4_LF1_Adam_Upsampled/weights.05-0.21.hdf5\"\n",
    "bce_chexpert_exp.model.load_weights(weights)\n",
    "predictions.append(bce_chexpert_exp.model.predict(bce_chexpert_exp.benchmark.testgen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = tf.math.reduce_mean(predictions, axis=0)\n",
    "predictions_bool = (y_pred >= 0.5)\n",
    "groundtruth_label = bce_chexpert_exp.benchmark.testgen.get_labels_nonan()\n",
    "\n",
    "for key, value in enumerate(columns_12):\n",
    "    pr = []\n",
    "    for sample in y_pred:\n",
    "        pr.append(sample[key])\n",
    "    m = tf.keras.metrics.AUC()\n",
    "    m.update_state(groundtruth_label[:, key], pr)\n",
    "    print(value, m.result().numpy())\n",
    "    \n",
    "m = tf.keras.metrics.AUC()\n",
    "m.update_state(groundtruth_label, y_pred)\n",
    "print(\"Average AUC: \", m.result().numpy())\n",
    "\n",
    "predictions_bool = np.array(predictions_bool, dtype=int)\n",
    "groundtruth_label = bce_chexpert_exp.benchmark.testgen.get_labels_nonan()\n",
    "report = classification_report(groundtruth_label, predictions_bool, target_names=bce_chexpert_exp.benchmark.label_columns)\n",
    "print('skelarn report: ', report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
