{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling already trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "basepath = Path(os.getcwd())\n",
    "# make sure your working directory is the repository root.\n",
    "if basepath.name != \"idp-radio-1\":\n",
    "    os.chdir(basepath.parent.parent.parent)\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "os.getcwd()\n",
    "\n",
    "import os \n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "# Specify which GPU(s) to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Or 2, 3, etc. other than 0\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(device_count={'GPU': 1}, allow_soft_placement=True, log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1.0\n",
    "tf.compat.v1.Session(config=config)\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet101V2\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from src.architectures.simple.simple_base import SimpleBaseArchitecture\n",
    "from src.architectures.adv.guendel19 import densenet\n",
    "import numpy as np\n",
    "\n",
    "from src.architectures.benchmarks.benchmark import Benchmark, Experiment\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from src.architectures.benchmarks.benchmark_definitions import Chexpert_Benchmark, Chestxray14_Benchmark, simple_architecture_experiment, generate_benchmarks, METRICS, SINGLE_CLASS_METRICS, CHEXPERT_COLUMNS, CHESTXRAY14_COLUMNS\n",
    "from src.metrics.metrics import F2Score\n",
    "from src.metrics.losses import WeightedBinaryCrossentropy, BinaryCrossentropy, compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinitialize benchmark that was used for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_12 = ['Enlarged Cardiomediastinum',\n",
    "                    'Cardiomegaly',\n",
    "                    'Lung Opacity',\n",
    "                    'Lung Lesion',\n",
    "                    'Edema',\n",
    "                    'Consolidation',\n",
    "                    'Pneumonia',\n",
    "                    'Atelectasis',\n",
    "                    'Pneumothorax',\n",
    "                    'Pleural Effusion',\n",
    "                    'Pleural Other',\n",
    "                    'Fracture']\n",
    "\n",
    "uzeros = ['Cardiomegaly',\n",
    "        'Enlarged Cardiomediastinum',\n",
    "        'Lung Opacity',\n",
    "        'Lung Lesion',\n",
    "        'Consolidation',\n",
    "        'Pneumothorax',\n",
    "        'Pleural Effusion']\n",
    "uones = ['Edema',\n",
    "        'Atelectasis',\n",
    "        'Fracture',\n",
    "        'Pleural Other',\n",
    "        'Pneumonia',]\n",
    "\n",
    "upsample_factors = {\n",
    "    \"Enlarged Cardiomediastinum\": 1,\n",
    "    \"Lung Lesion\":1,\n",
    "    \"Pleural Other\":2,\n",
    "    \"Fracture\":2,\n",
    "}\n",
    "\n",
    "transformations_2 = {\"unsharp_mask\":{\"radius\":2, \"amount\":1}}\n",
    "\n",
    "benchmark_params = {path = Path(os.environ.get(\"CHEXPERT_DATASET_DIRECTORY\")),\n",
    "                                             name=\"2_Chexpert_CWBCE_L1Normed_E5_B32_C0_N12_AugAffine_sharp21_U75_D256_DS9505_1LR4_LF1_Adam_Upsampled\",\n",
    "                                             classes=columns_12,\n",
    "                                             train_labels = \"train.csv\",\n",
    "                                             test_labels = \"test.csv\",\n",
    "                                             nan_replacement = 0, #float(\"NaN\"),\n",
    "                                             u_enc = [uzeros, uones],\n",
    "                                             epochs=5,\n",
    "                                             batch_size=32,\n",
    "                                             crop = False,\n",
    "                                             dim=(256, 256),\n",
    "                                             loss = BinaryCrossentropy(),\n",
    "                                             use_class_weights = False,\n",
    "                                             upsample_factors = upsample_factors,\n",
    "                                             metrics=METRICS,\n",
    "                                             single_class_metrics=SINGLE_CLASS_METRICS,\n",
    "                                             optimizer = Adam(learning_rate=1e-4, clipnorm=1),\n",
    "                                             lr_factor = 0.1,\n",
    "                                             augmentation = \"affine\",\n",
    "                                             transformations = transformations_2,\n",
    "                                             split_seed = 6122156,\n",
    "                                             split_valid_size = 0.05}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify which models you want to ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.densenet import DenseNet169, DenseNet121\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "\n",
    "ensemble = \n",
    "[[DenseNet169, tensorflow.keras.applications.densenet.preprocess_input, ''],\n",
    " [DenseNet121, tensorflow.keras.applications.densenet.preprocess_input, ''],\n",
    " [Xception, tensorflow.keras.applications.xception.preprocess_input, '']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we ensemble the model and make the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for member in ensemble: \n",
    "    benchmark_params['preprocess_input_fn'] = member[1]\n",
    "    bce_benchmark = Chexpert_Benchmark (**benchmark_params)\n",
    "    bce_benchmark.loss = WeightedBinaryCrossentropy(bce_benchmark.positive_weights,\n",
    "                                                    bce_benchmark.negative_weights)\n",
    "\n",
    "    bce_chexpert_exp = simple_architecture_experiment(bce_benchmark, member[0], bce_benchmark.label_columns)\n",
    "    bce_chexpert_exp.benchmark.traingen.shuffle = False\n",
    "    print(bce_chexpert_exp.benchmark.traingen.shuffle)\n",
    "\n",
    "    bce_chexpert_exp = Experiment(bce_benchmark, model)\n",
    "    bce_chexpert_exp.model.load_weights(member[2])\n",
    "    predictions.append(bce_chexpert_exp.model.predict(bce_chexpert_exp.benchmark.testgen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the average over all predictions and evaluate them with the known metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = tf.math.reduce_mean(predictions, axis=0)\n",
    "predictions_bool = (y_pred >= 0.5)\n",
    "\n",
    "for key, value in enumerate(columns_12):\n",
    "    pr = []\n",
    "    for sample in y_pred:\n",
    "        pr.append(sample[key])\n",
    "    m = tf.keras.metrics.AUC()\n",
    "    m.update_state(groundtruth_label[:, key], pr)\n",
    "    print(value, m.result().numpy())\n",
    "    \n",
    "m = tf.keras.metrics.AUC()\n",
    "m.update_state(groundtruth_label, y_pred)\n",
    "print(\"Average AUC: \", m.result().numpy())\n",
    "\n",
    "predictions_bool = np.array(predictions_bool, dtype=int)\n",
    "groundtruth_label = bce_chexpert_exp.benchmark.testgen.get_labels_nonan()\n",
    "report = classification_report(groundtruth_label, predictions_bool, target_names=bce_chexpert_exp.benchmark.label_columns)\n",
    "print('skelarn report: ', report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
