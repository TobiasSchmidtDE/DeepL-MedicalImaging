{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:04:00.0, compute capability: 7.5\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.4.0-dev20200815'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import tensorflow\n",
    "\n",
    "basepath = Path(os.getcwd())\n",
    "# make sure your working directory is the repository root.\n",
    "if basepath.name != \"idp-radio-1\":\n",
    "    os.chdir(basepath.parent.parent.parent)\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "os.getcwd()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Or 2, 3, etc. other than 0\n",
    "\n",
    "#config = tf.compat.v1.ConfigProto(device_count={'GPU': 2}, allow_soft_placement=True, log_device_placement=True)\n",
    "config = tensorflow.compat.v1.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 1.8\n",
    "tensorflow.compat.v1.Session(config=config)\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras import models\n",
    "import json\n",
    "from src.architectures.benchmarks.benchmark import Benchmark, Experiment\n",
    "from pathlib import Path\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from src.metrics.losses import WeightedBinaryCrossentropy, compute_class_weight\n",
    "\n",
    "from tensorflow.keras.backend import manual_variable_initialization \n",
    "manual_variable_initialization(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIFY WHICH EXPERIMENT TO LOAD BY INDEX IN EXPERIMENT-LOG.JSON\n",
    "ind = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chexpert_BCE_E3_B32_C0_N12_D256_DS9505_2LR1_LF5_SGD\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "with open(\"logs/unvalidated-experiment-log.json\") as f:\n",
    "  experiments = json.load(f)\n",
    "experiment = experiments['experiments'][ind]\n",
    "experiment_benchmark = experiments['experiments'][ind]['benchmark']\n",
    "\n",
    "experiment_benchmark['name'] = experiment_benchmark['benchmark_name']\n",
    "experiment_benchmark['dataset_folder'] = Path(experiment_benchmark['dataset_folder'])\n",
    "\n",
    "experiment_benchmark.pop('benchmark_name', None)\n",
    "experiment_benchmark.pop('num_samples_train', None)\n",
    "experiment_benchmark.pop('num_samples_validation', None)\n",
    "experiment_benchmark.pop('num_samples_test', None)\n",
    "\n",
    "if experiment_benchmark['optimizer'] == 'Adam':\n",
    "    lr = experiment_benchmark['learning_rate']\n",
    "    experiment_benchmark['optimizer'] = Adam(learning_rate=lr)\n",
    "    experiment_benchmark.pop('learning_rate', None)\n",
    "elif experiment_benchmark['optimizer'] == 'SGD':\n",
    "    lr = experiment_benchmark['learning_rate']\n",
    "    experiment_benchmark['optimizer'] = SGD(learning_rate=lr)\n",
    "    experiment_benchmark.pop('learning_rate', None)\n",
    "else:\n",
    "    raise NotImplementedError()\n",
    "\n",
    "posw = tensorflow.constant(experiment_benchmark['positive_weights'], dtype=tensorflow.float32)\n",
    "negw = tensorflow.constant(experiment_benchmark['negative_weights'], dtype=tensorflow.float32)\n",
    "\n",
    "experiment_benchmark.pop('positive_weights', None)\n",
    "experiment_benchmark.pop('negative_weights', None)\n",
    "\n",
    "experiment_benchmark['test_labels'] = \"test.csv\"\n",
    "\n",
    "benchmark = Benchmark(**experiment_benchmark)\n",
    "testgen = benchmark.testgen\n",
    "traingen = benchmark.traingen\n",
    "valgen = benchmark.valgen\n",
    "\n",
    "print(experiment_benchmark['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from src.metrics.metrics import SingleClassMetric, NaNWrapper\n",
    "\n",
    "path = os.path.join(\"models/\", experiment['name'], experiment['filename'])\n",
    "# reconstructed_model = models.load_model(path, custom_objects={'NaNWrapper': NaNWrapper})\n",
    "\n",
    "if experiment_benchmark['loss'] == \"weighted_binary_crossentropy\":\n",
    "    loss = WeightedBinaryCrossentropy(posw, negw)\n",
    "elif experiment_benchmark['loss'] == \"binary_crossentropy\":\n",
    "    loss = BinaryCrossentropy()\n",
    "else:\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234\n"
     ]
    }
   ],
   "source": [
    "# testgen.on_epoch_end()\n",
    "print(len(testgen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "thresholds = [0.3, 0.4, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_class_weight(traingen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 8s 35ms/step\n",
      "current threshold:  0.3\n",
      "TF Precision:  tf.Tensor(0.53846157, shape=(), dtype=float32)\n",
      "TF Recall:  tf.Tensor(0.23076923, shape=(), dtype=float32)\n",
      "current threshold:  0.4\n",
      "TF Precision:  tf.Tensor(0.53846157, shape=(), dtype=float32)\n",
      "TF Recall:  tf.Tensor(0.23076923, shape=(), dtype=float32)\n",
      "current threshold:  0.5\n",
      "TF Precision:  tf.Tensor(0.53846157, shape=(), dtype=float32)\n",
      "TF Recall:  tf.Tensor(0.23076923, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "groundtruth_label = testgen.get_labels_nonan()\n",
    "predictions = reconstructed_model.predict(testgen, steps=len(testgen), verbose=1)\n",
    "\n",
    "for t in thresholds:\n",
    "    print('current threshold: ', t)\n",
    "    predictions_bool = (predictions >= t)\n",
    "    y_pred = np.array(predictions_bool, dtype=int)\n",
    "\n",
    "    # report = classification_report(groundtruth_label, y_pred, target_names=list(CHEXPERT_BENCHMARKS['WBCE_E5_B32_C0'].label_columns))\n",
    "    # print('sklearn report: ', report)\n",
    "    \n",
    "    pre = Precision(thresholds=t)\n",
    "    pre.update_state(groundtruth_label, predictions_bool)\n",
    "    print('TF Precision: ', pre.result())\n",
    "    pre.reset_states()\n",
    "    \n",
    "    rec = Recall(thresholds=t)\n",
    "    rec.update_state(groundtruth_label, predictions_bool)\n",
    "    print('TF Recall: ', rec.result())\n",
    "    rec.reset_states()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for pred in y_pred:\n",
    "    print(pred)\n",
    "# groundtruth_label = testgen.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 1., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_labels = pd.read_csv(\"data/chexpert/full/test.csv\")\n",
    "\n",
    "columns = ['Enlarged Cardiomediastinum',\n",
    "                    'Cardiomegaly',\n",
    "                    'Lung Opacity',\n",
    "                    'Lung Lesion',\n",
    "                    'Edema',\n",
    "                    'Consolidation',\n",
    "                    'Pneumonia',\n",
    "                    'Atelectasis',\n",
    "                    'Pneumothorax',\n",
    "                    'Pleural Effusion',\n",
    "                    'Pleural Other',\n",
    "                    'Fracture']\n",
    "    \n",
    "gt_labels = test_labels[columns].to_numpy()\n",
    "\n",
    "img_paths = self.dataset.iloc[sample_ids][self.path_column].to_numpy()\n",
    "\n",
    "    img_paths = str(self.dataset_folder) + \"/\" + \\\n",
    "            self.path_column_prefix + img_paths\n",
    "\n",
    "        img_template_type = (self.dataset.iloc[sample_ids][self.view_pos_column]\n",
    "                             .replace({self.view_pos_frontal: \"frontal\",\n",
    "                                       self.view_pos_lateral: \"lateral\"})\n",
    "                             .to_numpy())\n",
    "\n",
    "        images = np.array([self.load_image(*args)\n",
    "                           for args in zip(img_paths, img_template_type)])\n",
    "\n",
    "        if self.preprocess_input_fn is not None:\n",
    "            images = self.preprocess_input_fn(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn report:                              precision    recall  f1-score   support\n",
      "\n",
      "Enlarged Cardiomediastinum       0.00      0.00      0.00       109\n",
      "              Cardiomegaly       0.00      0.00      0.00        68\n",
      "              Lung Opacity       0.54      1.00      0.70       126\n",
      "               Lung Lesion       0.00      0.00      0.00         1\n",
      "                     Edema       0.00      0.00      0.00        45\n",
      "             Consolidation       0.00      0.00      0.00        33\n",
      "                 Pneumonia       0.00      0.00      0.00         8\n",
      "               Atelectasis       0.00      0.00      0.00        80\n",
      "              Pneumothorax       0.00      0.00      0.00         8\n",
      "          Pleural Effusion       0.00      0.00      0.00        67\n",
      "             Pleural Other       0.00      0.00      0.00         1\n",
      "                  Fracture       0.00      0.00      0.00         0\n",
      "\n",
      "                 micro avg       0.54      0.23      0.32       546\n",
      "                 macro avg       0.04      0.08      0.06       546\n",
      "              weighted avg       0.12      0.23      0.16       546\n",
      "               samples avg       0.54      0.17      0.25       546\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(groundtruth_label, y_pred, target_names=benchmark.label_columns)\n",
    "print('sklearn report: ', report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_res = reconstructed_model.evaluate(\n",
    "            x=testgen, steps=len(testgen), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "basepath = Path(os.getcwd())\n",
    "# make sure your working directory is the repository root.\n",
    "if basepath.name != \"idp-radio-1\":\n",
    "    os.chdir(basepath.parent.parent.parent)\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "os.getcwd()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Or 2, 3, etc. other than 0\n",
    "\n",
    "#config = tf.compat.v1.ConfigProto(device_count={'GPU': 2}, allow_soft_placement=True, log_device_placement=True)\n",
    "config = tensorflow.compat.v1.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 1.8\n",
    "tensorflow.compat.v1.Session(config=config)\n",
    "tensorflow.__version__\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet101V2\n",
    "from src.architectures.simple.simple_base import SimpleBaseArchitecture\n",
    "from src.architectures.adv.guendel19 import densenet\n",
    "\n",
    "from src.architectures.benchmarks.benchmark import Benchmark, Experiment\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from src.architectures.benchmarks.benchmark_definitions import Chexpert_Benchmark, Chestxray14_Benchmark, simple_architecture_experiment, generate_benchmarks, METRICS, CHEXPERT_COLUMNS, CHESTXRAY14_COLUMNS\n",
    "from src.metrics.metrics import F2Score\n",
    "from src.metrics.losses import WeightedBinaryCrossentropy, compute_class_weight\n",
    "\n",
    "columns_5 =  ['Cardiomegaly',\n",
    "                'Edema',\n",
    "                'Consolidation',\n",
    "                'Atelectasis',\n",
    "                'Pleural Effusion']\n",
    "\n",
    "chexpert_benchmarks, _ = generate_benchmarks(path = Path(os.environ.get(\"CHEXPERT_DATASET_DIRECTORY\")),\n",
    "                                                     name_suffix=\"_D256_DS0595_savetest7\",\n",
    "                                                     classes=columns_5,\n",
    "                                                     # test_labels = \"test.csv\",\n",
    "                                                     split_valid_size = 0.2,\n",
    "                                                     split_test_size = 0.2,\n",
    "                                                     train_labels = \"train.csv\",\n",
    "                                                     # nan_replacement = -1, #float(\"NaN\"),\n",
    "                                                     batch_sizes = {\"b\": 32},\n",
    "                                                     epoch_sizes = {\"e\": 1},\n",
    "                                                     dim=(256, 256),\n",
    "                                                     crop = {\"C0\": False},\n",
    "                                                     split_seed = 6122156,\n",
    "                                                     augmentation=None)#\"affine\")\n",
    "testgen = chexpert_benchmarks[\"BCE_E1_B32_C0_N5_D256_DS0595_savetest7\"].testgen\n",
    "label_columns = chexpert_benchmarks[\"BCE_E1_B32_C0_N5_D256_DS0595_savetest7\"].label_columns\n",
    "del chexpert_benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "model = tensorflow.keras.models.load_model('models/DenseNet121_Chexpert_BCE_E1_B32_C0_N5_D256_DS0595_savetest7/DenseNet121_Chexpert_BCE_E1_B32_C0_N5_D256_DS0595_savetest7_20200819-125620.h5', compile=False)\n",
    "predstwo = model.predict(testgen, steps=len(testgen), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "groundtruth_label = testgen.get_labels_nonan()\n",
    "predictions_bool = (predstwo >= 0.5)\n",
    "y_pred = np.array(predictions_bool, dtype=int)\n",
    "report = classification_report(groundtruth_label, y_pred, target_names=label_columns)\n",
    "print('sklearn report: ', report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think something doesnt work with the masked loss function, I get really low values here. Fix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
