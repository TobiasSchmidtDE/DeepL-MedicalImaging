{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:04:00.0, compute capability: 7.5\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.4.0-dev20200815'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import tensorflow\n",
    "\n",
    "basepath = Path(os.getcwd())\n",
    "# make sure your working directory is the repository root.\n",
    "if basepath.name != \"idp-radio-1\":\n",
    "    os.chdir(basepath.parent.parent.parent)\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "os.getcwd()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Or 2, 3, etc. other than 0\n",
    "\n",
    "#config = tf.compat.v1.ConfigProto(device_count={'GPU': 2}, allow_soft_placement=True, log_device_placement=True)\n",
    "config = tensorflow.compat.v1.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 1.8\n",
    "tensorflow.compat.v1.Session(config=config)\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras import models\n",
    "import json\n",
    "from src.architectures.benchmarks.benchmark import Benchmark, Experiment\n",
    "from pathlib import Path\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from src.metrics.losses import WeightedBinaryCrossentropy, compute_class_weight\n",
    "\n",
    "from tensorflow.keras.backend import manual_variable_initialization \n",
    "manual_variable_initialization(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.architectures.simple.load_model import load_model\n",
    "\n",
    "model, benchmark = load_model(6, \"weights.05-0.21.hdf5\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "thresholds = [0.3, 0.4, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_class_weight(traingen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 8s 35ms/step\n",
      "current threshold:  0.3\n",
      "TF Precision:  tf.Tensor(0.53846157, shape=(), dtype=float32)\n",
      "TF Recall:  tf.Tensor(0.23076923, shape=(), dtype=float32)\n",
      "current threshold:  0.4\n",
      "TF Precision:  tf.Tensor(0.53846157, shape=(), dtype=float32)\n",
      "TF Recall:  tf.Tensor(0.23076923, shape=(), dtype=float32)\n",
      "current threshold:  0.5\n",
      "TF Precision:  tf.Tensor(0.53846157, shape=(), dtype=float32)\n",
      "TF Recall:  tf.Tensor(0.23076923, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "groundtruth_label = testgen.get_labels_nonan()\n",
    "predictions = reconstructed_model.predict(testgen, steps=len(testgen), verbose=1)\n",
    "\n",
    "for t in thresholds:\n",
    "    print('current threshold: ', t)\n",
    "    predictions_bool = (predictions >= t)\n",
    "    y_pred = np.array(predictions_bool, dtype=int)\n",
    "    \n",
    "    pre = Precision(thresholds=t)\n",
    "    pre.update_state(groundtruth_label, predictions_bool)\n",
    "    print('TF Precision: ', pre.result())\n",
    "    pre.reset_states()\n",
    "    \n",
    "    rec = Recall(thresholds=t)\n",
    "    rec.update_state(groundtruth_label, predictions_bool)\n",
    "    print('TF Recall: ', rec.result())\n",
    "    rec.reset_states()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(groundtruth_label, y_pred, target_names=benchmark.label_columns)\n",
    "print('skelarn report: ', report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_res = reconstructed_model.evaluate(x=testgen, stepes=len(testgen), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curve here and write function to get best threshold value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
