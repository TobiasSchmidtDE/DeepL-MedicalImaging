{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/srv/idp-radio-1')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import tensorflow as tf\n",
    "\n",
    "basepath = Path(os.getcwd())\n",
    "# make sure your working directory is the repository root.\n",
    "if basepath.name != \"idp-radio-1\":\n",
    "    os.chdir(basepath.parent.parent.parent)\n",
    "load_dotenv(find_dotenv())\n",
    "basepath = Path(os.getcwd())\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "basepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which GPU(s) to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Or 2, 3, etc. other than 0\n",
    "\n",
    "#config = tf.compat.v1.ConfigProto(device_count={'GPU': 1}, allow_soft_placement=True, log_device_placement=True)\n",
    "config = tf.compat.v1.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 1.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:04:00.0, compute capability: 7.5\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.4.0-dev20200815'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.compat.v1.Session(config=config)\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import traceback\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "from tensorflow.keras.applications import InceptionV3, Xception, DenseNet121, InceptionResNetV2, ResNet152V2, NASNetLarge\n",
    "from src.architectures.simple.simple_base import SimpleBaseArchitecture\n",
    "from src.architectures.simple.load_model import get_all_experiment_logs, get_experiment_from_logs, benchmark_from_logs, get_preprocessing_for_architecture, get_model_build_function, rebuild_experiment, difference_test_results, reevaluate_on_datagen\n",
    "from src.architectures.benchmarks.benchmark import Benchmark, Experiment\n",
    "from src.architectures.benchmarks.benchmark_definitions import generate_benchmarks,simple_architecture_experiment, Chexpert_Benchmark, CHEXPERT_COLUMNS, METRICS, SINGLE_CLASS_METRICS\n",
    "from src.metrics.metrics import F2Score\n",
    "from src.metrics.losses import WeightedBinaryCrossentropy, compute_class_weight\n",
    "from src.utils.save_model import get_experiment, load_model\n",
    "from src.metrics.metrics import SingleClassMetric, NaNWrapper, F2Score, FBetaScore\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments = get_all_experiment_logs()\n",
    "experiments = [exp for exp in experiments if \"Failed\" not in exp[\"name\"]]\n",
    "#experiments = [exp for exp in experiments if \"N12\" in exp[\"name\"]]\n",
    "experiments = [exp for exp in experiments if \"num_samples_test\" in exp[\"benchmark\"].keys() ]\n",
    "experiments = [exp for exp in experiments if exp[\"benchmark\"][\"num_samples_test\"] == 234 ]\n",
    "len(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('DenseNet121_Chexpert_CWBCE_L1Normed_E5_B32_C0_N12_AugAffine_sharp51_U75_D256_DS9505_1LR4_LF1_Adam_Upsampled',\n",
       " 0.7465326189994812)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_dict = experiments[-1].copy()\n",
    "exp_dict[\"name\"], exp_dict[\"test\"][\"auc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weights file DenseNet121_Chexpert_CWBCE_L1Normed_E5_B32_C0_N12_AugAffine_sharp51_U75_D256_DS9505_1LR4_LF1_Adam_Upsampled_20200906-065845.h5 to load model...\n"
     ]
    }
   ],
   "source": [
    "exp = rebuild_experiment(exp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reevaluate_aug(exp, average_over=10, new_metrics=True):\n",
    "    \n",
    "    testgen = exp.benchmark.testgen\n",
    "    testgen.augmentation = exp.benchmark.traingen.augmentation\n",
    "    \n",
    "    preds = np.zeros((10, len(testgen), 12))\n",
    "    for i in range(10):\n",
    "        preds[i] = exp.model.predict(\n",
    "            testgen, steps=len(testgen), verbose=1)\n",
    "    \n",
    "    preds = np.average(preds, axis=0)\n",
    "    \n",
    "    exp.groundtruth_label = testgen.get_labels_nonan()\n",
    "    \n",
    "    metric_results = {}\n",
    "    if new_metrics:\n",
    "        metrics = []\n",
    "        for m in exp.benchmark.metrics:\n",
    "            if isinstance(m, SingleClassMetric):\n",
    "                class_name = \"_\".join(m.name.split(\"_\")[1:])\n",
    "                metrics.append(SingleClassMetric(m.base_metric, m.class_id, class_name= class_name))\n",
    "            else:\n",
    "                extra_args = {}\n",
    "                if hasattr(m, \"multi_label\"):\n",
    "                    extra_args[\"multi_label\"] = m.multi_label\n",
    "                               \n",
    "                metrics.append(m.__class__(name= m.name, **extra_args))\n",
    "    else:\n",
    "        metrics = exp.benchmark.metrics\n",
    "    \n",
    "    for metric in metrics:\n",
    "        metric.reset_states()\n",
    "        metric.update_state(tensorflow.constant(exp.groundtruth_label), tensorflow.constant(preds))\n",
    "        metric_results[metric.name] = metric.result().numpy()\n",
    "        \n",
    "    return metric_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 6s 27ms/step\n",
      "234/234 [==============================] - 4s 18ms/step\n",
      "234/234 [==============================] - 4s 18ms/step\n",
      "234/234 [==============================] - 4s 18ms/step\n",
      "234/234 [==============================] - 4s 19ms/step\n",
      "234/234 [==============================] - 4s 18ms/step\n",
      "234/234 [==============================] - 4s 19ms/step\n",
      "234/234 [==============================] - 4s 18ms/step\n",
      "234/234 [==============================] - 4s 18ms/step\n",
      "234/234 [==============================] - 4s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "res = reevaluate_aug(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.00934445858001709,\n",
       " 'precision': 0.02370131015777588,\n",
       " 'recall': 0.003663003444671631,\n",
       " 'f2_score': 0.004427388310432434,\n",
       " 'binary_accuracy': 0.0010682344436645508,\n",
       " 'accuracy_enlarged_cardiomediastinum': 0.0,\n",
       " 'accuracy_cardiomegaly': 0.017094016075134277,\n",
       " 'accuracy_lung_opacity': 0.0,\n",
       " 'accuracy_lung_lesion': 0.004273474216461182,\n",
       " 'accuracy_edema': 0.0,\n",
       " 'accuracy_consolidation': 0.0,\n",
       " 'accuracy_pneumonia': 0.0,\n",
       " 'accuracy_atelectasis': 0.0,\n",
       " 'accuracy_pneumothorax': 0.0,\n",
       " 'accuracy_pleural_effusion': 0.008547008037567139,\n",
       " 'accuracy_pleural_other': 0.008547008037567139,\n",
       " 'accuracy_fracture': 0.0,\n",
       " 'auc_enlarged_cardiomediastinum': 0.02763301134109497,\n",
       " 'auc_cardiomegaly': 0.010364949703216553,\n",
       " 'auc_lung_opacity': 0.0033068060874938965,\n",
       " 'auc_lung_lesion': 0.18454933166503906,\n",
       " 'auc_edema': 0.00540846586227417,\n",
       " 'auc_consolidation': 0.0011307597160339355,\n",
       " 'auc_pneumonia': 0.020741164684295654,\n",
       " 'auc_atelectasis': 0.00831979513168335,\n",
       " 'auc_pneumothorax': 0.04646015167236328,\n",
       " 'auc_pleural_effusion': 0.003172755241394043,\n",
       " 'auc_pleural_other': 0.012875556945800781,\n",
       " 'auc_fracture': 0.0,\n",
       " 'precision_enlarged_cardiomediastinum': 0.0,\n",
       " 'precision_cardiomegaly': 0.125,\n",
       " 'precision_lung_opacity': 0.0,\n",
       " 'precision_lung_lesion': 0.0,\n",
       " 'precision_edema': 0.04024767875671387,\n",
       " 'precision_consolidation': 0.0,\n",
       " 'precision_pneumonia': 0.0,\n",
       " 'precision_atelectasis': 0.0,\n",
       " 'precision_pneumothorax': 0.08571429550647736,\n",
       " 'precision_pleural_effusion': 0.013888895511627197,\n",
       " 'precision_pleural_other': 0.0,\n",
       " 'precision_fracture': 0.0,\n",
       " 'recall_enlarged_cardiomediastinum': 0.0,\n",
       " 'recall_cardiomegaly': 0.05882352963089943,\n",
       " 'recall_lung_opacity': 0.0,\n",
       " 'recall_lung_lesion': 0.0,\n",
       " 'recall_edema': 0.02222222089767456,\n",
       " 'recall_consolidation': 0.0,\n",
       " 'recall_pneumonia': 0.0,\n",
       " 'recall_atelectasis': 0.0,\n",
       " 'recall_pneumothorax': 0.125,\n",
       " 'recall_pleural_effusion': 0.029850736260414124,\n",
       " 'recall_pleural_other': 0.0,\n",
       " 'recall_fracture': 0.0}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_test_results(res, exp_dict[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.73718816, 0.7465326189994812)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"auc\"], exp_dict[\"test\"][\"auc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
