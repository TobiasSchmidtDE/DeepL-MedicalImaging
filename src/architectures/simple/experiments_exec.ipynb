{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author: Tobias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main notebook we use for model training. Is it mainly used to instantiate a benchmark, run the training, do the evaluation and save the model as well as the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we do the usual setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "basepath = Path(os.getcwd())\n",
    "# make sure your working directory is the repository root.\n",
    "if basepath.name != \"idp-radio-1\":\n",
    "    os.chdir(basepath.parent.parent.parent)\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import tensorflow as tf\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this before loading other dependencies, otherwise they might occupy memory on gpu 0 by default and it will stay that way\n",
    "\n",
    "# Specify which GPU(s) to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Or 2, 3, etc. other than 0\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(device_count={'GPU': 1}, allow_soft_placement=True, log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1.0\n",
    "tf.compat.v1.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet101V2\n",
    "from src.architectures.simple.simple_base import SimpleBaseArchitecture\n",
    "from src.architectures.adv.guendel19 import densenet\n",
    "import numpy as np\n",
    "\n",
    "from src.architectures.benchmarks.benchmark import Benchmark, Experiment\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from src.architectures.benchmarks.benchmark_definitions import Chexpert_Benchmark, Chestxray14_Benchmark, simple_architecture_experiment, generate_benchmarks, METRICS, SINGLE_CLASS_METRICS, CHEXPERT_COLUMNS, CHESTXRAY14_COLUMNS\n",
    "from src.metrics.metrics import F2Score\n",
    "from src.metrics.losses import WeightedBinaryCrossentropy, BinaryCrossentropy, compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!remote_access/get_tunnels.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify subsets of the columns we want to train on as well as different uncertainty encodings and transformations that are then handed to the data generator and applied before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_12 = ['Enlarged Cardiomediastinum',\n",
    "                    'Cardiomegaly',\n",
    "                    'Lung Opacity',\n",
    "                    'Lung Lesion',\n",
    "                    'Edema',\n",
    "                    'Consolidation',\n",
    "                    'Pneumonia',\n",
    "                    'Atelectasis',\n",
    "                    'Pneumothorax',\n",
    "                    'Pleural Effusion',\n",
    "                    'Pleural Other',\n",
    "                    'Fracture']\n",
    "\n",
    "uzeros = ['Cardiomegaly',\n",
    "        'Enlarged Cardiomediastinum',\n",
    "        'Lung Opacity',\n",
    "        'Lung Lesion',\n",
    "        'Consolidation',\n",
    "        'Pneumothorax',\n",
    "        'Pleural Effusion']\n",
    "\n",
    "uones = ['Edema',\n",
    "        'Atelectasis',\n",
    "        'Fracture',\n",
    "        'Pleural Other',\n",
    "        'Pneumonia',]\n",
    "\n",
    "\n",
    "upsample_factors = {\n",
    "    \"Enlarged Cardiomediastinum\": 1,\n",
    "    \"Lung Lesion\":1,\n",
    "    #\"Pneumothorax\":1,\n",
    "    #\"Pneumonia\":1,\n",
    "    \"Pleural Other\":2,\n",
    "    \"Fracture\":2,\n",
    "}\n",
    "\n",
    "columns_5 =  ['Cardiomegaly',\n",
    "                'Edema',\n",
    "                'Consolidation',\n",
    "                'Atelectasis',\n",
    "                'Pleural Effusion']\n",
    "\n",
    "uzeros_5 = ['Cardiomegaly',\n",
    "        'Consolidation',\n",
    "        'Pleural Effusion']\n",
    "\n",
    "uones_5 = ['Edema',\n",
    "        'Atelectasis']\n",
    "\n",
    "\n",
    "upsample_factors_5 = {\n",
    "    \"Consolidation\":2,\n",
    "    \"Cardiomegaly\":1\n",
    "}\n",
    "\n",
    "transformations_0 = {\"hist_equalization\":{}}\n",
    "transformations_1 = { \"gaussian_blur\":{\"kernal_size\":3}, \"hist_equalization\":{}}\n",
    "transformations_2 = {\"unsharp_mask\":{\"radius\":2, \"amount\":1}}\n",
    "transformations_3 = {\"windowing\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_benchmark = Chexpert_Benchmark (path = Path(os.environ.get(\"CHEXPERT_DATASET_DIRECTORY\")),\n",
    "                                 name=\"Chexpert_BCE_E3_B32_C0_N12_AugAffine_Uones_D256_DS9505_2LR1_LF5_SGD_Upsampled\",\n",
    "                                 classes=columns_12,\n",
    "                                 train_labels = \"train.csv\",\n",
    "                                 test_labels = \"test.csv\",\n",
    "                                 nan_replacement = 0, #float(\"NaN\"),\n",
    "                                 u_enc = \"uones\",\n",
    "                                 epochs=3,\n",
    "                                 batch_size=32,\n",
    "                                 crop = False,\n",
    "                                 dim=(256, 256),\n",
    "                                 loss = BinaryCrossentropy(),\n",
    "                                 use_class_weights = False,\n",
    "                                 upsample_factors = upsample_factors,\n",
    "                                 metrics=METRICS,\n",
    "                                 single_class_metrics=SINGLE_CLASS_METRICS,\n",
    "                                 optimizer = SGD(learning_rate=2e-1, clipnorm=1),\n",
    "                                 lr_factor = 0.5,\n",
    "                                 augmentation = \"affine\",\n",
    "                                 transformations = {},\n",
    "                                 split_seed = 6122156,\n",
    "                                 split_valid_size = 0.05, \n",
    "                                 preprocess_input_fn = tf.keras.applications.densenet.preprocess_input)\n",
    "\n",
    "#bce_benchmark.loss = WeightedBinaryCrossentropy(bce_benchmark.positive_weights,\n",
    " #                                               bce_benchmark.negative_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_benchmark.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_chexpert_exp = simple_architecture_experiment(bce_benchmark, DenseNet121, bce_benchmark.label_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_chexpert_exp.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_chexpert_exp.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_chexpert_exp.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this benchmark to verify various aspects of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_class_weight(bce_chexpert_exp.benchmark.traingen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_weights = bce_chexpert_exp.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = bce_chexpert_exp.benchmark.traingen[0]\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bce_chexpert_exp.model(images, training=True)\n",
    "preds.op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_chexpert_exp.model.summary(line_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = -1\n",
    "trained_weights[index].shape, trained_weights[index], np.isnan(trained_weights[index]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_layers = [i for i in range(len(trained_weights)) if np.isnan(trained_weights[i]).any()] \n",
    "#nan_layers   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_weights = {i:np.abs(trained_weights[i]).mean() for i in range(len(trained_weights))}\n",
    "#mean_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{i:trained_weights[i].shape for i in range(len(trained_weights))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(191, 195):\n",
    "    print(i, trained_weights[i].shape, trained_weights[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chexpert_exp.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "model_filename = chexpert_exp.model_name + \"_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_filename_tf = model_filename + \".tf\"\n",
    "model_filename_h5 = model_filename + \".h5\"\n",
    "model_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath = Path(os.getcwd()) / 'models' / chexpert_exp.model_name\n",
    "path = folderpath / model_filename\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure path exists, ceate one if necessary\n",
    "Path(folderpath).mkdir(parents=True, exist_ok=True)\n",
    "chexpert_exp.model.save(path, save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure path exists, ceate one if necessary\n",
    "Path(folderpath).mkdir(parents=True, exist_ok=True)\n",
    "chexpert_exp.model.save(folderpath / model_filename_h5, save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath / model_filename_h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexpert_exp.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexpert_exp.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testgen = chexpert_benchmarks[\"BCE_E1_B32_C0_N5_D256_DS0595_savetest7\"].testgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = chexpert_exp.model.predict(testgen, steps=len(testgen), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "report = classification_report(groundtruth_label, y_pred, target_names=chexpert_benchmarks[\"BCE_E1_B32_C0_N5_D256_DS0595_savetest7\"].label_columns)\n",
    "print('sklearn report: ', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the benchmark class to evaluate models other than the base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_guendel_chestxray14 = densenet(classes=len(CHESTXRAY14_COLUMNS))\n",
    "model_guendel_chexpert = densenet(classes=len(CHEXPERT_COLUMNS))\n",
    "\n",
    "#experiment_guendel_chestxray14 = Experiment(chestxray14_benchmark, model_guendel_chestxray14)\n",
    "experiment_guendel_chexpert = Experiment(CHEXPERT_BENCHMARKS[\"WBCE_E10_B32\"], model_guendel_chexpert, model_name=\"test_WBCE_32\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment_guendel_chestxray14_result =  experiment_guendel_chestxray14.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_guendel_chexpert_result =  experiment_guendel_chexpert.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_guendel_chexpert.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_guendel_chexpert.save(upload=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
