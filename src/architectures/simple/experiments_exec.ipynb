{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/srv/idp-radio-1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "basepath = Path(os.getcwd())\n",
    "# make sure your working directory is the repository root.\n",
    "if basepath.name != \"idp-radio-1\":\n",
    "    os.chdir(basepath.parent.parent.parent)\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
    "from src.architectures.simple.simple_base import SimpleBase\n",
    "from src.architectures.benchmarks.benchmark import Benchmark, Experiment\n",
    "from src.architectures.adv.guendel19 import densenet\n",
    "from src.metrics.metrics import F2Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:1 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:08:00.0, compute capability: 7.5\n",
      "/job:localhost/replica:0/task:0/device:GPU:1 -> device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:42:00.0, compute capability: 7.5\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7f5bcf70e8d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify which GPU(s) to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Or 2, 3, etc. other than 0\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs open for the following services:\n",
      "[('tensorboard', 'http://e703f1318d95.ngrok.io'), ('jupyternotebook', 'http://63ad65c6873d.ngrok.io'), ('jupyterlab', 'http://cf6f79db15c5.ngrok.io')]\n"
     ]
    }
   ],
   "source": [
    "!remote_access/get_tunnels.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [tf.keras.metrics.AUC(name=\"AUC_ROC\", multi_label=True),\n",
    "           tf.keras.metrics.Precision(),\n",
    "           tf.keras.metrics.Recall(),\n",
    "           F2Score(),\n",
    "           tf.keras.metrics.BinaryAccuracy()\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'chexpert_full',\n",
       " 'dataset_folder': 'data/chexpert/full',\n",
       " 'models_dir': 'models',\n",
       " 'epochs': 10,\n",
       " 'optimizer': 'Adam',\n",
       " 'loss': 'binary_crossentropy',\n",
       " 'metrics': ['AUC', 'Precision', 'Recall', 'F2Score', 'BinaryAccuracy'],\n",
       " 'label_columns': ['No Finding',\n",
       "  'Enlarged Cardiomediastinum',\n",
       "  'Cardiomegaly',\n",
       "  'Lung Opacity',\n",
       "  'Lung Lesion',\n",
       "  'Edema',\n",
       "  'Consolidation',\n",
       "  'Pneumonia',\n",
       "  'Atelectasis',\n",
       "  'Pneumothorax',\n",
       "  'Pleural Effusion',\n",
       "  'Pleural Other',\n",
       "  'Fracture',\n",
       "  'Support Devices'],\n",
       " 'path_column': 'Path',\n",
       " 'path_column_prefix': '',\n",
       " 'shuffle': True,\n",
       " 'batch_size': 128,\n",
       " 'dim': (256, 256),\n",
       " 'n_channels': 3,\n",
       " 'nan_replacement': 0,\n",
       " 'unc_value': -1,\n",
       " 'u_enc': 'uzeroes',\n",
       " 'drop_last': True,\n",
       " 'train_num_samples': 142727,\n",
       " 'valid_num_samples': 35855,\n",
       " 'test_num_samples': 44832}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chexpert_columns = ['No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion',\n",
    "                       'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax',\n",
    "                       'Pleural Effusion', 'Pleural Other', 'Fracture', 'Support Devices']\n",
    "\n",
    "chexpert_benchmark = Benchmark(Path(os.environ.get(\"CHEXPERT_DATASET_DIRECTORY\")),\n",
    "                                  chexpert_columns,\n",
    "                                  epochs=10,\n",
    "                                  train_labels=\"train.csv\",\n",
    "                                  path_column=\"Path\",\n",
    "                                  split_group='patient_id',\n",
    "                                  batch_size=128,\n",
    "                                  metrics = metrics)\n",
    "chexpert_benchmark.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'chestxray14_scale_256',\n",
       " 'dataset_folder': 'data/chestxray14/scale_256',\n",
       " 'models_dir': 'models',\n",
       " 'epochs': 10,\n",
       " 'optimizer': 'Adam',\n",
       " 'loss': 'binary_crossentropy',\n",
       " 'metrics': ['AUC', 'Precision', 'Recall', 'F2Score', 'BinaryAccuracy'],\n",
       " 'label_columns': ['Edema',\n",
       "  'Atelectasis',\n",
       "  'Pneumonia',\n",
       "  'Pleural_Thickening',\n",
       "  'Cardiomegaly',\n",
       "  'Infiltration',\n",
       "  'Consolidation',\n",
       "  'Fibrosis',\n",
       "  'No Finding',\n",
       "  'Effusion',\n",
       "  'Nodule',\n",
       "  'Mass',\n",
       "  'Hernia',\n",
       "  'Emphysema',\n",
       "  'Pneumothorax'],\n",
       " 'path_column': 'Image Index',\n",
       " 'path_column_prefix': 'images/',\n",
       " 'shuffle': True,\n",
       " 'batch_size': 128,\n",
       " 'dim': (256, 256),\n",
       " 'n_channels': 3,\n",
       " 'nan_replacement': 0,\n",
       " 'unc_value': -1,\n",
       " 'u_enc': 'uzeroes',\n",
       " 'drop_last': True,\n",
       " 'train_num_samples': 72774,\n",
       " 'valid_num_samples': 17487,\n",
       " 'test_num_samples': 21859}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chestxray14_columns = ['Edema', 'Atelectasis', 'Pneumonia',\n",
    "                       'Pleural_Thickening', 'Cardiomegaly', 'Infiltration', 'Consolidation',\n",
    "                       'Fibrosis', 'No Finding', 'Effusion', 'Nodule', 'Mass', 'Hernia',\n",
    "                       'Emphysema', 'Pneumothorax']\n",
    "\n",
    "chestxray14_benchmark = Benchmark(Path(os.environ.get(\"CHESTXRAY14_DATASET_DIRECTORY\")),\n",
    "                                  chestxray14_columns,\n",
    "                                  epochs=10,\n",
    "                                  train_labels=\"meta/data/labels.csv\",\n",
    "                                  path_column=\"Image Index\",\n",
    "                                  path_column_prefix=\"images/\",\n",
    "                                  split_group='Patient ID',\n",
    "                                  batch_size=128,\n",
    "                                  metrics=metrics)\n",
    "chestxray14_benchmark.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_resnet_chestxray14 = SimpleBase(ResNet152V2, len(chestxray14_columns)).get_model()\n",
    "model_resnet_chexpert = SimpleBase(ResNet152V2, len(chexpert_columns)).get_model()\n",
    "\n",
    "model_densenet_chestxray14 = SimpleBase(DenseNet121, len(chestxray14_columns)).get_model()\n",
    "model_densenet_chexpert = SimpleBase(DenseNet121, len(chexpert_columns)).get_model()\n",
    "\n",
    "model_inceptionnet_chestxray14 = SimpleBase(InceptionV3, len(chestxray14_columns)).get_model()\n",
    "model_inceptionnet_chexpert = SimpleBase(InceptionV3, len(chexpert_columns)).get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_resnet_chexpert = Experiment(chexpert_benchmark, model_resnet_chexpert, \"ResNet152V2_CheXpert\")\n",
    "experiment_densenet_chexpert = Experiment(chexpert_benchmark, model_densenet_chexpert, \"DenseNet121_CheXpert\")\n",
    "experiment_inceptionnet_chexpert = Experiment(chexpert_benchmark, model_inceptionnet_chexpert, \"InceptionV3_CheXpert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_resnet_chestxray14 = Experiment(chestxray14_benchmark, model_resnet_chestxray14, \"ResNet152V2_ChestXray14\")\n",
    "experiment_densenet_chestxray14 = Experiment(chestxray14_benchmark, model_densenet_chestxray14, \"DenseNet121_ChestXray14\")\n",
    "experiment_inceptionnet_chestxray14 = Experiment(chestxray14_benchmark, model_inceptionnet_chestxray14, \"InceptionV3_ChestXray14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   1/1115 [..............................] - ETA: 0s - loss: 0.7224 - AUC_ROC: 0.5060 - precision: 0.1226 - recall: 0.3369 - f2_score: 0.2496 - binary_accuracy: 0.5212WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      " 372/1115 [=========>....................] - ETA: 8:32 - loss: 0.3279 - AUC_ROC: 0.6637 - precision: 0.6327 - recall: 0.4055 - f2_score: 0.4369 - binary_accuracy: 0.8629"
     ]
    }
   ],
   "source": [
    "experiment_resnet_chexpert_result =  experiment_resnet_chexpert.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 281 steps, validate for 68 steps\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "  5/281 [..............................] - ETA: 38:58 - loss: 3.3168 - categorical_crossentropy: 3.3168 - categorical_accuracy: 0.2664 - categorical_hinge: 0.9445"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Keras_worker_ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 347, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 398, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "KeyboardInterrupt\n",
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 463, in _handle_results\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 251, in recv\n",
      "    return _ForkingPickler.loads(buf.getbuffer())\n",
      "_pickle.UnpicklingError: invalid load key, '\\x96'.\n",
      "\n",
      "Process Keras_worker_ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 347, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 398, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "experiment_densenet_chexpert_result =  experiment_densenet_chexpert.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_inceptionnet_chexpert_result =  experiment_inceptionnet_chexpert.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_resnet_chestxray14_result =  experiment_resnet_chestxray14.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_densenet_chestxray14_result =  experiment_densenet_chestxray14.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_inceptionnet_chestxray14_result =  experiment_inceptionnet_chestxray14.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_guendel_chestxray14 = densenet(classes=len(chestxray14_columns))\n",
    "model_guendel_chexpert = densenet(classes=len(chexpert_columns))\n",
    "\n",
    "experiment_guendel_chestxray14 = Experiment(chestxray14_benchmark, model_guendel_chestxray14, \"Guendel19_ChestXray14\")\n",
    "experiment_guendel_chexpert = Experiment(chexpert_benchmark, model_resnet_chexpert, \"Guendel19_CheXpert\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_guendel_chestxray14_result =  experiment_guendel_chestxray14.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_guendel_chexpert_result =  experiment_guendel_chexpert.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                No Finding       0.20      0.67      0.30      4484\n",
      "Enlarged Cardiomediastinum       0.00      0.00      0.00      2110\n",
      "              Cardiomegaly       0.27      0.12      0.16      5353\n",
      "              Lung Opacity       0.58      0.44      0.50     21193\n",
      "               Lung Lesion       0.00      0.00      0.00      1769\n",
      "                     Edema       0.45      0.43      0.44     10323\n",
      "             Consolidation       0.00      0.00      0.00      2897\n",
      "                 Pneumonia       0.00      0.00      0.00      1183\n",
      "               Atelectasis       0.28      0.00      0.01      6797\n",
      "              Pneumothorax       0.12      0.00      0.00      4044\n",
      "          Pleural Effusion       0.55      0.76      0.64     17355\n",
      "             Pleural Other       0.00      0.00      0.00       687\n",
      "                  Fracture       0.24      0.01      0.02      1783\n",
      "           Support Devices       0.54      0.98      0.69     23378\n",
      "\n",
      "                 micro avg       0.48      0.52      0.50    103356\n",
      "                 macro avg       0.23      0.24      0.20    103356\n",
      "              weighted avg       0.43      0.52      0.43    103356\n",
      "               samples avg       0.46      0.48      0.44    103356\n",
      "\n",
      "{'loss': 5.3907987540108815, 'categorical_crossentropy': 5.390798568725586, 'categorical_accuracy': 0.10453125089406967, 'categorical_hinge': 0.7468773722648621}\n"
     ]
    }
   ],
   "source": [
    "train_result, eval_result, save_result = exp_result_resnet_chexpert\n",
    "print(eval_result[\"report\"])\n",
    "print(eval_result[\"metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'experiment_resnet_chexpert' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b479de81e35c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment_resnet_chexpert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalgen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment_resnet_chexpert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'experiment_resnet_chexpert' is not defined"
     ]
    }
   ],
   "source": [
    "valgen = experiment_resnet_chexpert.benchmark.valgen\n",
    "\n",
    "valgen.on_epoch_end()\n",
    "\n",
    "predictions = experiment_resnet_chexpert.model.predict(valgen, steps=len(valgen), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No Finding',\n",
       " 'Enlarged Cardiomediastinum',\n",
       " 'Cardiomegaly',\n",
       " 'Lung Opacity',\n",
       " 'Lung Lesion',\n",
       " 'Edema',\n",
       " 'Consolidation',\n",
       " 'Pneumonia',\n",
       " 'Atelectasis',\n",
       " 'Pneumothorax',\n",
       " 'Pleural Effusion',\n",
       " 'Pleural Other',\n",
       " 'Fracture',\n",
       " 'Support Devices']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions_bool = (predictions >= 0.5)\n",
    "\n",
    "y_pred = np.array(predictions_bool, dtype=int)\n",
    "\n",
    "groundtruth_label = valgen.get_encoded_labels()\n",
    "len(groundtruth_label[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Finding\n",
      "true negatives:  22072\n",
      "false negatives:  1073\n",
      "true positives:  2268\n",
      "false positives:  10171\n",
      "\n",
      "Enlarged Cardiomediastinum\n",
      "true negatives:  33764\n",
      "false negatives:  1820\n",
      "true positives:  0\n",
      "false positives:  0\n",
      "\n",
      "Cardiomegaly\n",
      "true negatives:  29913\n",
      "false negatives:  3883\n",
      "true positives:  495\n",
      "false positives:  1293\n",
      "\n",
      "Lung Opacity\n",
      "true negatives:  13091\n",
      "false negatives:  9549\n",
      "true positives:  7567\n",
      "false positives:  5377\n",
      "\n",
      "Lung Lesion\n",
      "true negatives:  34120\n",
      "false negatives:  1463\n",
      "true positives:  1\n",
      "false positives:  0\n",
      "\n",
      "Edema\n",
      "true negatives:  23048\n",
      "false negatives:  4760\n",
      "true positives:  3621\n",
      "false positives:  4155\n",
      "\n",
      "Consolidation\n",
      "true negatives:  33197\n",
      "false negatives:  2387\n",
      "true positives:  0\n",
      "false positives:  0\n",
      "\n",
      "Pneumonia\n",
      "true negatives:  34633\n",
      "false negatives:  951\n",
      "true positives:  0\n",
      "false positives:  0\n",
      "\n",
      "Atelectasis\n",
      "true negatives:  30317\n",
      "false negatives:  5193\n",
      "true positives:  15\n",
      "false positives:  59\n",
      "\n",
      "Pneumothorax\n",
      "true negatives:  32315\n",
      "false negatives:  3266\n",
      "true positives:  1\n",
      "false positives:  2\n",
      "\n",
      "Pleural Effusion\n",
      "true negatives:  13109\n",
      "false negatives:  3274\n",
      "true positives:  10218\n",
      "false positives:  8983\n",
      "\n",
      "Pleural Other\n",
      "true negatives:  35041\n",
      "false negatives:  543\n",
      "true positives:  0\n",
      "false positives:  0\n",
      "\n",
      "Fracture\n",
      "true negatives:  33932\n",
      "false negatives:  1570\n",
      "true positives:  12\n",
      "false positives:  70\n",
      "\n",
      "Support Devices\n",
      "true negatives:  1299\n",
      "false negatives:  424\n",
      "true positives:  18004\n",
      "false positives:  15857\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "cm = sklearn.metrics.multilabel_confusion_matrix(groundtruth_label, y_pred)\n",
    "for i in range(14):\n",
    "    print(experiment_resnet_chexpert.benchmark.label_columns[i])\n",
    "    print(\"true negatives: \", cm[i, 0,0])\n",
    "    print(\"false negatives: \", cm[i, 1,0])\n",
    "    print(\"true positives: \", cm[i, 1,1])\n",
    "    print(\"false positives: \", cm[i, 0,1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Edema       0.03      0.55      0.06       432\n",
      " Atelectasis       0.11      0.82      0.19      2368\n",
      "   Pneumonia       0.02      0.41      0.03       277\n",
      "   Emphysema       0.02      0.00      0.01       456\n",
      "\n",
      "   micro avg       0.07      0.65      0.13      3533\n",
      "   macro avg       0.04      0.45      0.07      3533\n",
      "weighted avg       0.08      0.65      0.14      3533\n",
      " samples avg       0.08      0.10      0.09      3533\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(groundtruth_label, y_pred, target_names=list(resnet_chestxray.benchmark.label_columns))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valgen = resnet_chestxray.benchmark.valgen\n",
    "STEP_SIZE_EVAL = len(valgen.index) // valgen.batch_size\n",
    "print(len(valgen.index))\n",
    "STEP_SIZE_EVAL // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "271/271 [==============================] - 75s 276ms/step - loss: 0.2603 - categorical_crossentropy: 0.2603 - categorical_accuracy: 0.2547 - categorical_hinge: 1.7244\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eval_res = resnet_chestxray.model.evaluate(x=valgen, steps=STEP_SIZE_EVAL, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.26028381849938104,\n",
       " 0.26028382778167725,\n",
       " 0.25472787022590637,\n",
       " 1.7244476079940796]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[float (i) for i in eval_res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fd2951b82103>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "             Edema       0.00      0.00      0.00       455\n",
      "       Atelectasis       0.07      0.00      0.00      2207\n",
      "         Pneumonia       0.00      0.00      0.00       276\n",
      "         Emphysema       0.00      0.00      0.00       466\n",
      "      Pneumothorax       0.00      0.00      0.00      1018\n",
      "Pleural_Thickening       0.00      0.00      0.00       654\n",
      "      Cardiomegaly       0.00      0.00      0.00       546\n",
      "      Infiltration       0.18      1.00      0.30      3981\n",
      "     Consolidation       0.00      0.00      0.00       963\n",
      "          Fibrosis       0.00      0.00      0.00       333\n",
      "        No Finding       0.54      1.00      0.70     12130\n",
      "          Effusion       0.26      0.18      0.21      2626\n",
      "            Nodule       0.00      0.00      0.00      1351\n",
      "              Mass       0.00      0.00      0.00      1257\n",
      "            Hernia       0.00      0.00      0.00        52\n",
      "\n",
      "         micro avg       0.36      0.59      0.44     28315\n",
      "         macro avg       0.07      0.15      0.08     28315\n",
      "      weighted avg       0.29      0.59      0.36     28315\n",
      "       samples avg       0.36      0.68      0.46     28315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(resnet_chestxray.evaluation_result[\"report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.metrics._classification.classification_report(y_true, y_pred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.50      0.50      0.50         2\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         6\n",
      "   macro avg       0.38      0.62      0.46         6\n",
      "weighted avg       0.33      0.50      0.39         6\n",
      " samples avg       0.39      0.50      0.43         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.array([[1,0,0,0], [0,1,0,1], [1,1,0,1]])\n",
    "y_true = np.array([[0,0,1,1], [0,1,1,0], [1,0,0,1]])\n",
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3e2e8b78f3e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmock_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmock_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmock_truth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "mock_predictions = tf.constant([[0., 0., 0.5, 1.], [0.8, 0.1, 0.2, 0.1]])\n",
    "mock_truth = tf.constant([[0., 0., 1., 1.], [1., 0., 1., 0.]])\n",
    "\n",
    "tf.constant(1.) - mock_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_id = 0\n",
    "single_pathology_pred = mock_predictions[:, label_id]\n",
    "p = tf.stack([mock_predictions, 1. - mock_predictions], 1)\n",
    "t = tf.stack([mock_truth, 1. - mock_truth], 1)\n",
    "sum_bc=0\n",
    "for i in range(4):\n",
    "    sum_bc = tf.keras.losses.BinaryCrossentropy()(t[:, :, i], p[:, :, i])\n",
    "sum_bc/4\n",
    "t.dtype == tf.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def mean_bce(y_true, y_pred):\n",
    "    print(\"y_true\", y_true)\n",
    "    print(\"y_pred\", y_pred)\n",
    "    if y_true.dtype == tf.float32 and y_pred.dtype == tf.float32:\n",
    "        p = tf.stack([y_pred, tf.constant(1.) - y_pred], 1)\n",
    "        t = tf.stack([y_true, tf.constant(1.) - y_true], 1)\n",
    "        sum_bc=0\n",
    "        for i in range(4):\n",
    "            sum_bc = tf.keras.losses.BinaryCrossentropy()(t[:, :, i], p[:, :, i])\n",
    "        return sum_bc/4\n",
    "    else:\n",
    "        print(\"WARNING: not type float32\")\n",
    "        return 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.6895466"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [[0., 1.], [1., 0.]]\n",
    "y_pred = [[1, 0], [1., 0]]\n",
    "# Using 'auto'/'sum_over_batch_size' reduction type.\n",
    "bce = tf.keras.losses.BinaryCrossentropy()\n",
    "bce(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Frontal/Lateral</th>\n",
       "      <th>AP/PA</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00001/study1/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>68</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study2/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>87</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>83</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>83</td>\n",
       "      <td>Lateral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00006/study1/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Path     Sex  Age  \\\n",
       "0   CheXpert-v1.0-small/train/patient00001/study1/...  Female   68   \n",
       "1   CheXpert-v1.0-small/train/patient00002/study2/...  Female   87   \n",
       "2   CheXpert-v1.0-small/train/patient00002/study1/...  Female   83   \n",
       "3   CheXpert-v1.0-small/train/patient00002/study1/...  Female   83   \n",
       "11  CheXpert-v1.0-small/train/patient00006/study1/...  Female   42   \n",
       "\n",
       "   Frontal/Lateral AP/PA  No Finding  Enlarged Cardiomediastinum  \\\n",
       "0          Frontal    AP         1.0                         NaN   \n",
       "1          Frontal    AP         NaN                         NaN   \n",
       "2          Frontal    AP         NaN                         NaN   \n",
       "3          Lateral   NaN         NaN                         NaN   \n",
       "11         Frontal    AP         1.0                         0.0   \n",
       "\n",
       "    Cardiomegaly  Lung Opacity  Lung Lesion  Edema  Consolidation  Pneumonia  \\\n",
       "0            NaN           NaN          NaN    NaN            NaN        NaN   \n",
       "1           -1.0           1.0          NaN   -1.0           -1.0        NaN   \n",
       "2            NaN           1.0          NaN    NaN           -1.0        NaN   \n",
       "3            NaN           1.0          NaN    NaN           -1.0        NaN   \n",
       "11           NaN           NaN          NaN    NaN            NaN        NaN   \n",
       "\n",
       "    Atelectasis  Pneumothorax  Pleural Effusion  Pleural Other  Fracture  \\\n",
       "0           NaN           0.0               NaN            NaN       NaN   \n",
       "1          -1.0           NaN              -1.0            NaN       1.0   \n",
       "2           NaN           NaN               NaN            NaN       1.0   \n",
       "3           NaN           NaN               NaN            NaN       1.0   \n",
       "11          NaN           NaN               0.0            NaN       NaN   \n",
       "\n",
       "    Support Devices  patient_id  \n",
       "0               1.0           1  \n",
       "1               NaN           2  \n",
       "2               NaN           2  \n",
       "3               NaN           2  \n",
       "11              NaN           6  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.preprocessing.split.train_test_split import train_test_split\n",
    "dataset_folder= Path(os.environ.get(\"CHEXPERT_DATASET_DIRECTORY\")) \n",
    "train_valid_labels = pd.read_csv( dataset_folder/ \"train.csv\")\n",
    "train_labels, validation_labels = train_test_split(train_valid_labels)\n",
    "\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.datasets.generator import ImageDataGenerator\n",
    "chexpert_columns = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity']\n",
    "\n",
    "train_generator = ImageDataGenerator(dataset=train_labels,\n",
    "                               dataset_folder=dataset_folder,\n",
    "                               label_columns=chexpert_columns,\n",
    "                               batch_size=32)\n",
    "\n",
    "eval_generator = ImageDataGenerator(dataset=validation_labels,\n",
    "                               dataset_folder=dataset_folder,\n",
    "                               label_columns=chexpert_columns,\n",
    "                               batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_data_labels = train_generator[0]\n",
    "eval_data, eval_data_labels = eval_generator[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow._api.v2.version' from '/usr/local/lib/python3.6/dist-packages/tensorflow/_api/v2/version/__init__.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from src.metrics.metrics import F2Score\n",
    "\n",
    "metrics = [tf.keras.metrics.AUC(name=\"AUC_ROC\", multi_label=True),\n",
    "           tf.keras.metrics.Precision(),\n",
    "           tf.keras.metrics.Recall(),\n",
    "           F2Score(),\n",
    "           tf.keras.metrics.BinaryAccuracy()\n",
    "          ]\n",
    "model_chexpert = SimpleBase(ResNet152V2, len(chexpert_columns)).get_model()\n",
    "model_chexpert.compile(optimizer=Adam(),\n",
    "                           loss= \"binary_crossentropy\",\n",
    "                           metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " 4/32 [==>...........................] - ETA: 0s - loss: 0.0041 - AUC_ROC: 0.6667 - precision_2: 1.0000 - recall_2: 1.0000 - f2_score_1: 1.0000 - binary_accuracy: 1.0000    "
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "2 root error(s) found.\n  (0) Not found:  Resource localhost/_AnonymousVar1687/N10tensorflow22SummaryWriterInterfaceE does not exist.\n\t [[{{node cond_5/then/_140/batch_loss}}]]\n  (1) Not found:  Resource localhost/_AnonymousVar1687/N10tensorflow22SummaryWriterInterfaceE does not exist.\n\t [[{{node cond_5/then/_140/batch_loss}}]]\n\t [[assert_less_equal_4/Assert/AssertGuard/else/_123/assert_less_equal_4/Assert/AssertGuard/Assert/data_1/_218]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_55586]\n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e11ec8d9128a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                    \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                                    callbacks=[tensorboard_callback, early_stopping_callback])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1088\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1089\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    764\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    791\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2809\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2810\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2811\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2813\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1836\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1837\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1838\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1912\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1914\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1915\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1916\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    550\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) Not found:  Resource localhost/_AnonymousVar1687/N10tensorflow22SummaryWriterInterfaceE does not exist.\n\t [[{{node cond_5/then/_140/batch_loss}}]]\n  (1) Not found:  Resource localhost/_AnonymousVar1687/N10tensorflow22SummaryWriterInterfaceE does not exist.\n\t [[{{node cond_5/then/_140/batch_loss}}]]\n\t [[assert_less_equal_4/Assert/AssertGuard/else/_123/assert_less_equal_4/Assert/AssertGuard/Assert/data_1/_218]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_55586]\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_dir = Path(\"models/\") / \"resnet_test9\"\n",
    "log_dir = model_dir / \"10\"\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "tensorboard_callback = TensorBoard(log_dir=str(log_dir),\n",
    "                                   update_freq= 5,\n",
    "                                   histogram_freq=1,\n",
    "                                   write_graph=False,\n",
    "                                   embeddings_freq=1,\n",
    "                                   profile_batch=0)\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                                           patience=3)\n",
    "train_results = model_chexpert.fit(x=train_data,\n",
    "                                   y=train_data_labels,\n",
    "                                   steps_per_epoch=len(train_data),\n",
    "                                   validation_data=(eval_data, eval_data_labels),\n",
    "                                   validation_steps=len(eval_data),\n",
    "                                   epochs=15,\n",
    "                                   callbacks=[tensorboard_callback, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[0. , 0. , 0.5, 1. ],\n",
       "       [0.8, 0.1, 0.2, 0.1]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred = tf.constant([[0., 0., 0.5, 1.], [0.8, 0.1, 0.2, 0.1]])\n",
    "y_true = tf.constant([[0., 0., 1., 1.], [1., 0., 1., 0.]])\n",
    "\n",
    "epsilon = tf.constant(1e-07)\n",
    "p_weight = tf.constant(0.5)\n",
    "n_weight = tf.constant(0.5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[          -inf,           -inf,  3.4657347e-01, -5.9604641e-08],\n",
       "       [ 1.1157169e-01, -1.6512926e+00,  8.0471867e-01, -1.6512926e+00]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bces = -(p_weight * y_true * tf.math.log(y_pred+epsilon) +\n",
    "                   n_weight * (1 - y_true) * (1 - tf.math.log(y_pred) + epsilon))\n",
    "bces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[-0.0000000e+00, -0.0000000e+00, -3.4657347e-01,  5.9604641e-08],\n",
       "       [-1.1157169e-01, -0.0000000e+00, -8.0471867e-01, -0.0000000e+00]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_weight * y_true * tf.math.log(y_pred+epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[ 5.9604641e-08,  5.9604641e-08, -0.0000000e+00, -0.0000000e+00],\n",
       "       [-0.0000000e+00, -5.2680206e-02, -0.0000000e+00, -5.2680206e-02]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_weight * (1 - y_true) * tf.math.log((1 - y_pred) + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[-1.6118095e+01, -1.6118095e+01, -6.9314694e-01,  1.1920928e-07],\n",
       "       [-2.2314338e-01, -2.3025842e+00, -1.6094373e+00, -2.3025842e+00]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.log(y_pred+epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_1 \n",
      " tf.Tensor([0.2 0.8], shape=(2,), dtype=float32)\n",
      "true_1 \n",
      " tf.Tensor([0. 1.], shape=(2,), dtype=float32)\n",
      "pred_2 \n",
      " tf.Tensor([0.  0.1], shape=(2,), dtype=float32)\n",
      "true_2 \n",
      " tf.Tensor([0. 0.], shape=(2,), dtype=float32)\n",
      "\n",
      "tf.Tensor(0.22314338, shape=(), dtype=float32)\n",
      "tf.Tensor(0.052680206, shape=(), dtype=float32)\n",
      "tf.Tensor(0.22314338, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1379118, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1379118, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = tf.constant([[0.2, 0.], [0.8, 0.1]])\n",
    "y_true = tf.constant([[0., 0.], [1., 0.]])\n",
    "\n",
    "\n",
    "p = tf.stack([y_pred, tf.constant(1.) - y_pred], 1)\n",
    "t = tf.stack([y_true, tf.constant(1.) - y_true], 1)\n",
    "for i in range(2):\n",
    "    print(\"pred_\"+str(i+1), \"\\n\", y_pred[:,  i])\n",
    "    print(\"true_\"+str(i+1), \"\\n\", y_true[:,  i])\n",
    "    \n",
    "print()\n",
    "pred_1= tf.constant([[0.2, 0.8]])\n",
    "true_1= tf.constant([[0., 1.]])\n",
    "\n",
    "pred_2 = tf.constant([[0., 0.1]])\n",
    "true_2 = tf.constant([[0., 0.]])\n",
    "\n",
    "l1 = tf.keras.losses.BinaryCrossentropy()(true_1,pred_1)\n",
    "l2 = tf.keras.losses.BinaryCrossentropy()(true_2,pred_2)\n",
    "testl = tf.keras.losses.BinaryCrossentropy()(test_true,test_pred)\n",
    "all_l = tf.keras.losses.BinaryCrossentropy()(y_true,y_pred)\n",
    "print(l1)\n",
    "print(l2)\n",
    "print(testl)\n",
    "print((l1 + l2)/2)\n",
    "print(all_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.22314338, shape=(), dtype=float32)\n",
      "tf.Tensor(0.052680146, shape=(), dtype=float32)\n",
      "tf.Tensor(0.22314338, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.python.ops import math_ops\n",
    "def custom_bce(y_t, y_p):\n",
    "    bce = y_t * math_ops.log(y_p + epsilon)\n",
    "    bce += (1 - y_t) * math_ops.log(1 - y_p + epsilon)\n",
    "    return tf.reduce_mean(-bce)\n",
    "\n",
    "print(custom_bce(true_1,pred_1))\n",
    "print(custom_bce(true_2,pred_2))\n",
    "print(custom_bce(test_true,test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "3.0\n",
      "tf.Tensor(0.8333334, shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8333334"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from src.metrics.metrics import F2Score, MeanBinaryAccuracy\n",
    "y_pred = tf.constant([[0.2, 0.3, 1.], [0.8, 0.1, 1.]])\n",
    "y_true = tf.constant([[0., 1., 1.], [1., 0., 1.]])\n",
    "\n",
    "TN = tf.keras.metrics.TrueNegatives()\n",
    "_ = TN.update_state(y_true,y_pred)\n",
    "\n",
    "TP = tf.keras.metrics.TruePositives()\n",
    "_ = TP.update_state(y_true,y_pred)\n",
    "\n",
    "print(TN.result().numpy())\n",
    "print(TP.result().numpy())\n",
    "print(tf.reduce_mean(tf.keras.metrics.binary_accuracy(y_true, y_pred)))\n",
    "\n",
    "Prec = tf.keras.metrics.BinaryAccuracy()\n",
    "_ = Prec.update_state(y_true,y_pred)\n",
    "Prec.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8333334>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multitask_accuracy ( y_true, y_pred, ):\n",
    "    return tf.reduce_mean(tf.keras.metrics.binary_accuracy(y_true, y_pred, threshold=0.5))\n",
    "multitask_accuracy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78947365"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "f2score = F2Score()\n",
    "_ = f2score.update_state(y_true,y_pred)\n",
    "f2score.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
